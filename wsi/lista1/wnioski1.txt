W ramach eksperymentu przeprowadzono trening prostej sieci neuronowej (SimpleNN) na zbiorze danych MNIST, którego celem było rozpoznanie cyfr na podstawie obrazów o rozdzielczości 28x28 pikseli.
Sieć neuronowa została wytrenowana przez 5 epok, a jej dokładność została oceniona na zbiorze testowym. W sprawozdaniu przedstawiam wyniki eksperymentu oraz interpretację uzyskanych rezultatów, w tym ocenę współczynnika prawidłowej rozpoznawalności, czułości i precyzji.

Tak wygląda output w terminalu z przeprowadzonego treningu:
PS K:\studia\sem4\wsi> & K:/Python/python.exe k:/studia/sem4/wsi/lista1/zad1.py
Epoka 1/5, Strata: 0.7575088624379782
Epoka 2/5, Strata: 0.36692697666029434
Epoka 3/5, Strata: 0.32274143252450266
Epoka 4/5, Strata: 0.29706951730382214
Epoka 5/5, Strata: 0.27562837984198446
Dokładność na zbiorze testowym: 92.72%
Czułość (Recall): 0.9260845511152815
Precyzja (Precision): 0.9270139128464436

Oznacza to, że model poprawnie sklasyfikował 92.72% przypadków testowych. Jest to dobry wynik, biorąc pod uwagę, że model jest stosunkowo prosty i opiera się na klasyfikacji jedynie za pomocą dwóch warstw (wejściowej i ukrytej) Model wykazuje się dużą zdolnością do generalizowania, ponieważ jego dokładność na zbiorze testowym jest wysoka, co sugeruje, że nauczył się dobrze rozpoznawać cyfry. Strata na każdym etapie treningu stopniowo malała, co oznacza, że model poprawiał swoje prognozy oraz uczył się coraz lepiej dopasowywać do danych treningowych, a wagi były skutecznie aktualizowane.

Czułość określa jak dobrze nasz klasyfikator określa klasę dla przypadków z tej klasy. W kontekście MNIST, czułość jest miarą tego, jak dobrze model rozpoznaje cyfry jako część właściwej klasy. Tutaj otrzymano wynik: 92,6 %


Precyzja określa jak dobrze klasyfikator przypisuje przypadki do danej klasy. W kontekście MNIST oznacza to, ile spośród przewidywanych przez model cyfr było rzeczywiście poprawnych. Wynik po treningu wynosi: 92,7% 

Jak możemy zauważyć zarówno czułość jak i precyzja są bardzo zbliżone do ogólnej dokładności, co oznacza, że model nie jest silnie stronniczy w kierunku jednej klasy.