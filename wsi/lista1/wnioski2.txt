Testowania sieci neuronowej na własnym zbiorze cyfr

Celem eksperymentu było sprawdzenie, jak wytrenowana sieć neuronowa reaguje na własnoręcznie przygotowany zbiór próbek cyfr. W tym celu przygotowano zestaw obrazów zawierających cyfry od 0 do 9, po trzy egzemplarze każdej cyfry. 

Wyniki: 
Po przeprowadzeniu testów na własnym zbiorze danych uzyskano następujące wyniki:

Dokładność rozpoznawania: 13,33%

Prawdziwe etykiety cyfr: [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 0, 0, 0]

Przewidywane etykiety: [7, 0, 2, 1, 2, 5, 2, 3, 2, 2, 9, 4, 7, 5, 2, 2, 7, 8, 8, 4, 8, 1, 2, 3, 5, 2, 2, 2, 5, 2]


Uzyskana dokładność na poziomie 13,33% wskazuje na bardzo słabe rozpoznawanie ręcznych cyfr przez sieć. Do możliwych przyczyn niskiej skuteczności zalicza się: 

Niezgodność danych treningowych i testowych – model był trenowany na danych MNIST, które zawierają cyfry pisane w jednolitym stylu, natomiast testowe próbki pochodziły od jednej osoby, co mogło wpłynąć na różnice w kształtach znaków.

Zbyt prosty model – sieć posiada jedynie jedną warstwę ukrytą, co może być niewystarczające do skutecznego rozpoznawania bardziej złożonych i niestandardowych wzorców.

Eksperyment pokazał, że sieć wytrenowana na zbiorze MNIST ma trudności z rozpoznawaniem cyfr pisanych ręcznie przez jedną osobę.

Pomimo niskiej skuteczności, eksperyment dostarczył cennych informacji na temat ograniczeń prostych modeli neuronowych i znaczenia jakości danych treningowych w problemach klasyfikacji obrazów.