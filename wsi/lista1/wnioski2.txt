Testowania sieci neuronowej na własnym zbiorze cyfr

Celem eksperymentu było sprawdzenie, jak wytrenowana sieć neuronowa reaguje na własnoręcznie przygotowany zbiór próbek cyfr. W tym celu przygotowano zestaw obrazów zawierających cyfry od 0 do 9, po trzy egzemplarze każdej cyfry. 

Wyniki: 
Po przeprowadzeniu testów na własnym zbiorze danych uzyskano następujące wyniki:

Dokładność na zbiorze testowym: 16.666666666666668%
----------Prawdziwe cyfry dla obrazów: [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 0, 0, 0]
Przewidywane cyfry dla Twoich obrazów: [2, 9, 8, 1, 4, 8, 3, 4, 6, 8, 8, 1, 5, 5, 8, 8, 8, 2, 8, 5, 6, 8, 8, 5, 8, 8, 2, 8, 2, 8]


Uzyskana dokładność na poziomie 13,33% wskazuje na bardzo słabe rozpoznawanie ręcznych cyfr przez sieć. Do możliwych przyczyn niskiej skuteczności zalicza się: 

Niezgodność danych treningowych i testowych – model był trenowany na danych MNIST, które zawierają cyfry pisane w jednolitym stylu, natomiast testowe próbki pochodziły od jednej osoby, co mogło wpłynąć na różnice w kształtach znaków.

Zbyt prosty model – sieć posiada jedynie jedną warstwę ukrytą, co może być niewystarczające do skutecznego rozpoznawania bardziej złożonych i niestandardowych wzorców.

Eksperyment pokazał, że sieć wytrenowana na zbiorze MNIST ma trudności z rozpoznawaniem cyfr pisanych ręcznie przez jedną osobę.

Pomimo niskiej skuteczności, eksperyment dostarczył cennych informacji na temat ograniczeń prostych modeli neuronowych i znaczenia jakości danych treningowych w problemach klasyfikacji obrazów.